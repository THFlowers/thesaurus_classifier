Log of experimental changes to code and effects on the match percentage etc.

// Before modifying if-idf to use log and num_docs

Loading 'SEWordSim-r1.db' into ram
Transferring data into in memory database
Beginning experiments

Match percentage, Zeros percentage, Average score, Filter Threshold %, Num similar terms, Min similarity %,
50.24385838150289, 6.015173410404624, 58.61599042916772, 0.1, 0, 0
50.24385838150289, 6.015173410404624, 58.61599042916772, 0.1, 0, 5
50.24385838150289, 6.015173410404624, 58.61599042916772, 0.1, 0, 10
50.24385838150289, 6.015173410404624, 58.61599042916772, 0.1, 0, 15
50.24385838150289, 6.015173410404624, 58.61599042916772, 0.1, 0, 20
50.24385838150289, 6.015173410404624, 58.61599042916772, 0.1, 5, 0
50.24385838150289, 6.015173410404624, 58.61599042916772, 0.1, 5, 5
50.24385838150289, 6.015173410404624, 58.61599042916772, 0.1, 5, 10
50.24385838150289, 6.015173410404624, 58.61599042916772, 0.1, 5, 15
50.24385838150289, 6.015173410404624, 58.61599042916772, 0.1, 5, 20
50.24385838150289, 6.015173410404624, 58.61599042916772, 0.1, 10, 0
50.24385838150289, 6.015173410404624, 58.61599042916772, 0.1, 10, 5
50.24385838150289, 6.015173410404624, 58.61599042916772, 0.1, 10, 10
50.24385838150289, 6.015173410404624, 58.61599042916772, 0.1, 10, 15
50.24385838150289, 6.015173410404624, 58.61599042916772, 0.1, 10, 20
46.33309248554913, 9.149205202312139, 50.979357086945804, 0.6, 0, 0
46.33309248554913, 9.149205202312139, 50.979357086945804, 0.6, 0, 5
46.33309248554913, 9.149205202312139, 50.979357086945804, 0.6, 0, 10
46.33309248554913, 9.149205202312139, 50.979357086945804, 0.6, 0, 15
46.33309248554913, 9.149205202312139, 50.979357086945804, 0.6, 0, 20
46.33309248554913, 9.149205202312139, 50.979357086945804, 0.6, 5, 0
46.33309248554913, 9.149205202312139, 50.979357086945804, 0.6, 5, 5
46.33309248554913, 9.149205202312139, 50.979357086945804, 0.6, 5, 10
46.33309248554913, 9.149205202312139, 50.979357086945804, 0.6, 5, 15
46.33309248554913, 9.149205202312139, 50.979357086945804, 0.6, 5, 20
46.33309248554913, 9.149205202312139, 50.979357086945804, 0.6, 10, 0
46.33309248554913, 9.149205202312139, 50.979357086945804, 0.6, 10, 5
46.33309248554913, 9.149205202312139, 50.979357086945804, 0.6, 10, 10
46.33309248554913, 9.149205202312139, 50.979357086945804, 0.6, 10, 15
46.33309248554913, 9.149205202312139, 50.979357086945804, 0.6, 10, 20
43.162933526011564, 11.949060693641618, 44.06536576606798, 1.1, 0, 0
43.162933526011564, 11.949060693641618, 44.06536576606798, 1.1, 0, 5
43.162933526011564, 11.949060693641618, 44.06536576606798, 1.1, 0, 10
43.162933526011564, 11.949060693641618, 44.06536576606798, 1.1, 0, 15
43.162933526011564, 11.949060693641618, 44.06536576606798, 1.1, 0, 20
43.162933526011564, 11.949060693641618, 44.06536576606798, 1.1, 5, 0
43.162933526011564, 11.949060693641618, 44.06536576606798, 1.1, 5, 5
43.162933526011564, 11.949060693641618, 44.06536576606798, 1.1, 5, 10
43.162933526011564, 11.949060693641618, 44.06536576606798, 1.1, 5, 15
43.162933526011564, 11.949060693641618, 44.06536576606798, 1.1, 5, 20
43.162933526011564, 11.949060693641618, 44.06536576606798, 1.1, 10, 0
43.162933526011564, 11.949060693641618, 44.06536576606798, 1.1, 10, 5
43.162933526011564, 11.949060693641618, 44.06536576606798, 1.1, 10, 10
43.162933526011564, 11.949060693641618, 44.06536576606798, 1.1, 10, 15
43.162933526011564, 11.949060693641618, 44.06536576606798, 1.1, 10, 20
39.83020231213873, 14.794075144508671, 39.723982884037596, 1.6, 0, 0
39.83020231213873, 14.794075144508671, 39.723982884037596, 1.6, 0, 5
39.83020231213873, 14.794075144508671, 39.723982884037596, 1.6, 0, 10
39.83020231213873, 14.794075144508671, 39.723982884037596, 1.6, 0, 15
39.83020231213873, 14.794075144508671, 39.723982884037596, 1.6, 0, 20
39.83020231213873, 14.794075144508671, 39.723982884037596, 1.6, 5, 0
39.83020231213873, 14.794075144508671, 39.723982884037596, 1.6, 5, 5
39.83020231213873, 14.794075144508671, 39.723982884037596, 1.6, 5, 10
39.83020231213873, 14.794075144508671, 39.723982884037596, 1.6, 5, 15
39.83020231213873, 14.794075144508671, 39.723982884037596, 1.6, 5, 20
39.83020231213873, 14.794075144508671, 39.723982884037596, 1.6, 10, 0
39.83020231213873, 14.794075144508671, 39.723982884037596, 1.6, 10, 5
39.83020231213873, 14.794075144508671, 39.723982884037596, 1.6, 10, 10
39.83020231213873, 14.794075144508671, 39.723982884037596, 1.6, 10, 15
39.83020231213873, 14.794075144508671, 39.723982884037596, 1.6, 10, 20
36.78648843930636, 17.602962427745666, 35.46741938767325, 2.1, 0, 0
36.78648843930636, 17.602962427745666, 35.46741938767325, 2.1, 0, 5
36.78648843930636, 17.602962427745666, 35.46741938767325, 2.1, 0, 10
36.78648843930636, 17.602962427745666, 35.46741938767325, 2.1, 0, 15
36.78648843930636, 17.602962427745666, 35.46741938767325, 2.1, 0, 20
36.78648843930636, 17.602962427745666, 35.46741938767325, 2.1, 5, 0
36.78648843930636, 17.602962427745666, 35.46741938767325, 2.1, 5, 5
36.78648843930636, 17.602962427745666, 35.46741938767325, 2.1, 5, 10
36.78648843930636, 17.602962427745666, 35.46741938767325, 2.1, 5, 15
36.78648843930636, 17.602962427745666, 35.46741938767325, 2.1, 5, 20
36.78648843930636, 17.602962427745666, 35.46741938767325, 2.1, 10, 0
36.78648843930636, 17.602962427745666, 35.46741938767325, 2.1, 10, 5
36.78648843930636, 17.602962427745666, 35.46741938767325, 2.1, 10, 10
36.78648843930636, 17.602962427745666, 35.46741938767325, 2.1, 10, 15
36.78648843930636, 17.602962427745666, 35.46741938767325, 2.1, 10, 20
32.98410404624278, 22.534320809248555, 31.22732217405269, 2.6, 0, 0
32.98410404624278, 22.534320809248555, 31.22732217405269, 2.6, 0, 5
32.98410404624278, 22.534320809248555, 31.22732217405269, 2.6, 0, 10
32.98410404624278, 22.534320809248555, 31.22732217405269, 2.6, 0, 15
32.98410404624278, 22.534320809248555, 31.22732217405269, 2.6, 0, 20
32.98410404624278, 22.534320809248555, 31.22732217405269, 2.6, 5, 0
32.98410404624278, 22.534320809248555, 31.22732217405269, 2.6, 5, 5
32.98410404624278, 22.534320809248555, 31.22732217405269, 2.6, 5, 10
32.98410404624278, 22.534320809248555, 31.22732217405269, 2.6, 5, 15
32.98410404624278, 22.534320809248555, 31.22732217405269, 2.6, 5, 20
32.98410404624278, 22.534320809248555, 31.22732217405269, 2.6, 10, 0
32.98410404624278, 22.534320809248555, 31.22732217405269, 2.6, 10, 5
32.98410404624278, 22.534320809248555, 31.22732217405269, 2.6, 10, 10
32.98410404624278, 22.534320809248555, 31.22732217405269, 2.6, 10, 15
32.98410404624278, 22.534320809248555, 31.22732217405269, 2.6, 10, 20
29.42557803468208, 26.427023121387283, 27.491503915210217, 3.1, 0, 0
29.42557803468208, 26.427023121387283, 27.491503915210217, 3.1, 0, 5
29.42557803468208, 26.427023121387283, 27.491503915210217, 3.1, 0, 10
29.42557803468208, 26.427023121387283, 27.491503915210217, 3.1, 0, 15
29.42557803468208, 26.427023121387283, 27.491503915210217, 3.1, 0, 20
29.42557803468208, 26.427023121387283, 27.491503915210217, 3.1, 5, 0
29.42557803468208, 26.427023121387283, 27.491503915210217, 3.1, 5, 5
29.42557803468208, 26.427023121387283, 27.491503915210217, 3.1, 5, 10
29.42557803468208, 26.427023121387283, 27.491503915210217, 3.1, 5, 15
29.42557803468208, 26.427023121387283, 27.491503915210217, 3.1, 5, 20
29.42557803468208, 26.427023121387283, 27.491503915210217, 3.1, 10, 0
29.42557803468208, 26.427023121387283, 27.491503915210217, 3.1, 10, 5
29.42557803468208, 26.427023121387283, 27.491503915210217, 3.1, 10, 10
29.42557803468208, 26.427023121387283, 27.491503915210217, 3.1, 10, 15
29.42557803468208, 26.427023121387283, 27.491503915210217, 3.1, 10, 20
23.067196531791907, 30.527456647398843, 21.57495369414608, 3.6, 0, 0
23.067196531791907, 30.527456647398843, 21.57495369414608, 3.6, 0, 5
23.067196531791907, 30.527456647398843, 21.57495369414608, 3.6, 0, 10
23.067196531791907, 30.527456647398843, 21.57495369414608, 3.6, 0, 15
23.067196531791907, 30.527456647398843, 21.57495369414608, 3.6, 0, 20
23.067196531791907, 30.527456647398843, 21.57495369414608, 3.6, 5, 0
23.067196531791907, 30.527456647398843, 21.57495369414608, 3.6, 5, 5
23.067196531791907, 30.527456647398843, 21.57495369414608, 3.6, 5, 10
23.067196531791907, 30.527456647398843, 21.57495369414608, 3.6, 5, 15

Match percentage, Zeros percentage, Average score, Filter Threshold %, Num similar terms, Min similarity %,
52.01408959537572, 4.055274566473988, 59.78274787967926, 0.0, 0, 0
50.24385838150289, 6.015173410404624, 58.61599042916772, 0.1, 0, 0
49.3768063583815, 6.945447976878612, 57.157194789946246, 0.2, 0, 0
48.53684971098266, 7.6860549132947975, 55.71506664172168, 0.3, 0, 0
47.98591040462428, 8.101517341040463, 54.150683620630126, 0.4, 0, 0
47.20917630057804, 8.309248554913294, 52.361393533810194, 0.5, 0, 0
46.33309248554913, 9.149205202312139, 50.979357086945804, 0.6, 0, 0
45.429913294797686, 10.223988439306359, 49.18579818819377, 0.7, 0, 0
44.93316473988439, 10.494942196531792, 47.829103587484845, 0.8, 0, 0
44.337066473988436, 10.621387283236995, 46.28647331463882, 0.9, 0, 0
43.67774566473989, 10.829118497109826, 45.128067225203964, 1.0, 0, 0

Match percentage, Zeros percentage, Average score, Filter Threshold %, Num similar terms, Min similarity %,
52.01408959537572, 4.055274566473988, 59.78274787967926, 0.0, 0, 0
52.01408959537572, 4.055274566473988, 59.78274787967926, 0.0, 0, 5
52.01408959537572, 4.055274566473988, 59.78274787967926, 0.0, 0, 10
52.01408959537572, 4.055274566473988, 59.78274787967926, 0.0, 0, 15
52.01408959537572, 4.055274566473988, 59.78274787967926, 0.0, 0, 20
52.01408959537572, 4.055274566473988, 59.78274787967926, 0.0, 5, 0
52.01408959537572, 4.055274566473988, 59.78274787967926, 0.0, 5, 5
52.01408959537572, 4.055274566473988, 59.78274787967926, 0.0, 5, 10
52.01408959537572, 4.055274566473988, 59.78274787967926, 0.0, 5, 15
52.01408959537572, 4.055274566473988, 59.78274787967926, 0.0, 5, 20
52.01408959537572, 4.055274566473988, 59.78274787967926, 0.0, 10, 0
52.01408959537572, 4.055274566473988, 59.78274787967926, 0.0, 10, 5
52.01408959537572, 4.055274566473988, 59.78274787967926, 0.0, 10, 10
52.01408959537572, 4.055274566473988, 59.78274787967926, 0.0, 10, 15
52.01408959537572, 4.055274566473988, 59.78274787967926, 0.0, 10, 20


// After modifying if-idf to use log and num_docs (log(num_docs/term_frequency for class))

50.63222543352601, 4.055274566473988, 2590.5460296111846, 0.0, 0, 0
50.63222543352601, 4.055274566473988, 2590.5460296111846, 0.0, 0, 5
50.63222543352601, 4.055274566473988, 2590.5460296111846, 0.0, 0, 10
50.63222543352601, 4.055274566473988, 2590.5460296111846, 0.0, 0, 15
50.63222543352601, 4.055274566473988, 2590.5460296111846, 0.0, 0, 20
50.63222543352601, 4.055274566473988, 2590.5460296111846, 0.0, 5, 0
50.63222543352601, 4.055274566473988, 2590.5460296111846, 0.0, 5, 5
50.63222543352601, 4.055274566473988, 2590.5460296111846, 0.0, 5, 10
50.63222543352601, 4.055274566473988, 2590.5460296111846, 0.0, 5, 15
50.63222543352601, 4.055274566473988, 2590.5460296111846, 0.0, 5, 20
50.63222543352601, 4.055274566473988, 2590.5460296111846, 0.0, 10, 0
50.63222543352601, 4.055274566473988, 2590.5460296111846, 0.0, 10, 5
50.63222543352601, 4.055274566473988, 2590.5460296111846, 0.0, 10, 10
50.63222543352601, 4.055274566473988, 2590.5460296111846, 0.0, 10, 15
50.63222543352601, 4.055274566473988, 2590.5460296111846, 0.0, 10, 20

// Experiment not filtering out tokens with non-alphabetic characters, and rolling back log / num_docs edit
// (currently only keeping 100% alphabetic)
// Also, found bug in make_model not calling lower() while ingesting documents from training data

53.88367052023121, 2.1947254335260116, 73.52120929959187, 0.0, 0, 0
53.88367052023121, 2.1947254335260116, 73.52120929959187, 0.0, 0, 5
53.88367052023121, 2.1947254335260116, 73.52120929959187, 0.0, 0, 10
53.88367052023121, 2.1947254335260116, 73.52120929959187, 0.0, 0, 15
53.88367052023121, 2.1947254335260116, 73.52120929959187, 0.0, 0, 20
53.88367052023121, 2.1947254335260116, 73.52120929959187, 0.0, 5, 0

// Parameters beyond filter_threshold have no effect
// Attempted to add third party lib (compound-word-splitter 0.4) to split compound words, ex 'artfactory' to ['art', 'factory']
// Can't install it, due to pyenchant not installing, due to path bullshit from msys2

// Found word-segmentation library instead, slightly harder to use, but installs in a snap
// http://www.grantjenks.com/docs/wordsegment/
// Appears to also be somewhat slower and slightly worse results, ~0.3% drop in accuracy right off the bat

53.567557803468205, 2.1947254335260116, 88.57577092795144, 0.0, 0, 0
53.567557803468205, 2.1947254335260116, 88.57577092795144, 0.0, 0, 5
53.567557803468205, 2.1947254335260116, 88.57577092795144, 0.0, 0, 10
53.567557803468205, 2.1947254335260116, 88.57577092795144, 0.0, 0, 15
53.567557803468205, 2.1947254335260116, 88.57577092795144, 0.0, 0, 20
53.567557803468205, 2.1947254335260116, 88.57577092795144, 0.0, 5, 0
53.567557803468205, 2.1947254335260116, 88.57577092795144, 0.0, 5, 5
53.567557803468205, 2.1947254335260116, 88.57577092795144, 0.0, 5, 10
53.567557803468205, 2.1947254335260116, 88.57577092795144, 0.0, 5, 15

// Disabling database and segmentation in categorize_test, but leaving segmentation in make model (also turn off loops)
53.73013005780347, 2.1947254335260116, 74.8979063446185, 0.0, 1, 0

// Also disabling segmentation in make model
53.88367052023121, 2.1947254335260116, 73.52120929959187, 0.0, 1, 0

// Taking above and ignoring 'uninformative' data while creating model
51.01156069364162, 3.3236994219653178, 82.15953133601701, 0.0, 1, 0

// Rolling back last entry, then putting segmentation back, but only keeping the segments
// Don't keep the original compounds, that is artdecade --> ['art', 'decade'], not --> ['artdecade', 'art', 'decade']
52.51986994219653, 2.348265895953757, 82.00363196308129, 0.0, 1, 0

// Cleaned up code to eliminate bunch of weak warnings, somehow without changing anything of substance we get to 53.9%
// Also, score up to 90.4 and zeros down to 2.19%
**********   53.91979768786127, 2.1947254335260116, 90.42822331033872, 0.0, 1, 0    **********

// So lets enable database and segmenting again. See if there is any change
53.84754335260116, 2.1947254335260116, 132.42155383378042, 0.0, 1, 0

// So what now?  Is there something wrong with DB and merge code?  Why does merge never run?  Why is DB useless?
// Should I ignore terms that are too common across all classes?  If so then at what rate?
// Should I switch to scikit learn, and use their n-gram tools?
// How about resurrecting the old project, making a third model (say scikit learn above), then using a best out of 3 system?
// Also see if any rest-apis from Monday 2/24 are useful, and if pandas makes parsing easier

// First need to bone up on VSM, NLP, tf-idf, etc. via Datacamp


// Write down what we have done, take snapshots of crap database
// Investigate word embeddings instead
// Several similarity scores are really high but make no sense
// Lower scores make sense, but it not strictly synonyms, can be antonyms, vaguely related and substrings of each other
// Ex isbn and penguin are highly related, due to book publishing

// We bought into the fact a paper was published we thought results were good,
// didn't check GIGO should have checked DB quality first

// Go over paper, domain specific word2vec (software engineering)
// Both extrapolated from stack overflow (1.5GB)

// Also look over word2vec tutorial / articles on datacamp

// Make job application plan, how to prep
// MS committee members (Chakraborty, Chris Mills, Sharanya)
TODO: Check if I had a class with Duan, Mike Bermeister, Andy Wang, Wally
// Set date and reserve room


// Descending min-similarity percentage (higher scores due to enabling segmenting)
53.84754335260116, 2.1947254335260116, 132.42155383378042, 0.0, 1, 100
53.84754335260116, 2.1947254335260116, 132.42155383378042, 0.0, 1, 95
53.84754335260116, 2.1947254335260116, 132.42155383378042, 0.0, 1, 90
53.84754335260116, 2.1947254335260116, 132.42155383378042, 0.0, 1, 85
53.84754335260116, 2.1947254335260116, 132.42155383378042, 0.0, 1, 80
53.84754335260116, 2.1947254335260116, 132.42155383378042, 0.0, 1, 75
53.84754335260116, 2.1947254335260116, 132.42155383378042, 0.0, 6, 100
53.84754335260116, 2.1947254335260116, 132.42155383378042, 0.0, 6, 95
53.84754335260116, 2.1947254335260116, 132.42155383378042, 0.0, 6, 90
53.84754335260116, 2.1947254335260116, 132.42155383378042, 0.0, 6, 85
53.84754335260116, 2.1947254335260116, 132.42155383378042, 0.0, 6, 80
53.84754335260116, 2.1947254335260116, 132.42155383378042, 0.0, 6, 75


// Implement gensim version, many code simplifications / refactors (short tests show same results as before fo DB)
53.13403179190752, 2.1947254335260116, 145.30285838293656, 0.0, 1, 65
53.04371387283237, 2.1947254335260116, 146.55820204978664, 0.0, 1, 60
52.97145953757225, 2.1947254335260116, 148.79557850777562, 0.0, 1, 55

Extremely slow, 3-4 hours per iteration.  But parameters actually have an effect.
This is after normalizing to reduce load time and ram usage (and hopefully speed things up)

Normalizing code:
from gensim.models import KeyedVectors
model = KeyedVectors.load_word2vec_format("SO_vectors_200.bin", binary=True)
model.init_sims(replace=True)
model.save("SO_vectors_normed")  # also results in a *.vectors.npy file, 103M for normed, 1.4G for vectors

Also, the gensim library makes no use of my expensive new GPU, but it does use all 8 cores to about 70%
Can still play video and do other tasks but must be careful of ram usage and cpu spikes
Already had BSOD once, due to driver thread getting stuck

Will attempt to use annoy library now to speed up queries

from gensim.similarities.index import AnnoyIndexer
annoy_index = AnnoyIndexer(model, 2)
annoy_index.save('SO_vectors_normed_annoy_index')

53.793352601156066, 2.1947254335260116, 127.71074962439191, 0.0, 1, 65
53.793352601156066, 2.1947254335260116, 127.71074962439191, 0.0, 1, 60
53.793352601156066, 2.1947254335260116, 127.71326347313949, 0.0, 1, 55
53.80238439306358, 2.1947254335260116, 132.70892946743945, 0.0, 6, 65
53.45917630057804, 2.1947254335260116, 139.9829274044642, 0.0, 6, 60
53.070809248554916, 2.1947254335260116, 149.07924587404807, 0.0, 6, 55

Now like 5 min per iteration, slightly more ram used.
Results match a little better but min_similarity has lost much sensitivity
Obvious when you think about it, annoy_index is approximate nearest neighbor fetching

Just questionable how much limiting topn query response and using list comprehension instead of loop affects results and speed
We will ignore this as the gain in speed is rather good

Not sure if model indexer number has any effect, so generating anew (in code, no file) with 3 to test:

53.793352601156066, 2.1947254335260116, 127.70948517352485, 0.0, 1, 65
53.793352601156066, 2.1947254335260116, 127.7100270810393, 0.0, 1, 60
53.793352601156066, 2.1947254335260116, 127.7100270810393, 0.0, 1, 55
53.67593930635838, 2.1947254335260116, 133.67766441445303, 0.0, 6, 65
53.161127167630056, 2.1947254335260116, 141.77858472537636, 0.0, 6, 60
52.537933526011564, 2.1947254335260116, 153.52620649686938, 0.0, 6, 55

Not the most conclusive (given terrible min_similiarity percentages) but looks like higher gives worse results
Also, looks like we may be able to go faster as this code only uses 15-20% cpu, instead of 70+% (across all logical processers)

Large step run w2v, with Filter Threshold % sweep:
53.793352601156066, 2.1947254335260116, 127.70903358392948, 0.0, 1, 90
53.793352601156066, 2.1947254335260116, 127.70903358392948, 0.0, 1, 85
53.793352601156066, 2.1947254335260116, 127.70903358392948, 0.0, 1, 80
53.793352601156066, 2.1947254335260116, 127.70953033248439, 0.0, 1, 75
53.793352601156066, 2.1947254335260116, 127.71056898855376, 0.0, 1, 70
53.793352601156066, 2.1947254335260116, 127.72155014221465, 0.0, 6, 90
53.80238439306358, 2.1947254335260116, 127.74521117906441, 0.0, 6, 85
*********53.92882947976879, 2.1947254335260116, 128.66369033282862, 0.0, 6, 80**********
53.91076589595376, 2.1947254335260116, 128.92473836475824, 0.0, 6, 75
53.90173410404624, 2.1947254335260116, 129.67426082668126, 0.0, 6, 70
51.79732658959538, 3.910765895953757, 125.27435712995465, 0.1, 1, 90
51.79732658959538, 3.910765895953757, 125.27435712995465, 0.1, 1, 85
51.79732658959538, 3.910765895953757, 125.27435712995465, 0.1, 1, 80
51.79732658959538, 3.910765895953757, 125.27435712995465, 0.1, 1, 75
51.79732658959538, 3.910765895953757, 125.27435712995465, 0.1, 1, 70
51.79732658959538, 3.910765895953757, 125.2825384281242, 0.1, 6, 90
51.79732658959538, 3.910765895953757, 125.29796924459825, 0.1, 6, 85

Only partially done before quitting, clear that filter_threshold is indeed useless
New peak of ~53.93% around 0.0, 6, 80.  Will sweep with more precision around there

Match percentage, Zeros percentage, Average score, Filter Threshold %, Num similar terms, Min similarity %,
53.793352601156066, 2.1947254335260116, 127.70903358392948, 0.0, 3, 95
53.793352601156066, 2.1947254335260116, 127.70903358392948, 0.0, 3, 94
53.793352601156066, 2.1947254335260116, 127.72155014221465, 0.0, 3, 93
53.793352601156066, 2.1947254335260116, 127.72155014221465, 0.0, 3, 92
53.793352601156066, 2.1947254335260116, 127.72155014221465, 0.0, 3, 91
53.793352601156066, 2.1947254335260116, 127.72155014221465, 0.0, 3, 90
53.793352601156066, 2.1947254335260116, 127.72158024818768, 0.0, 3, 89
53.793352601156066, 2.1947254335260116, 127.72200173181002, 0.0, 3, 88
53.793352601156066, 2.1947254335260116, 127.72337155358268, 0.0, 3, 87
53.80238439306358, 2.1947254335260116, 127.7387281803374, 0.0, 3, 86
53.8114161849711, 2.1947254335260116, 127.74397414613702, 0.0, 3, 85
53.8114161849711, 2.1947254335260116, 127.74916742648385, 0.0, 3, 84
53.793352601156066, 2.1947254335260116, 127.81413525610125, 0.0, 3, 83
53.91979768786127, 2.1947254335260116, 127.83426486231517, 0.0, 3, 82
*********53.9378612716763, 2.1947254335260116, 128.59444756256295, 0.0, 3, 81**************
*********53.9378612716763, 2.1947254335260116, 128.66153506772397, 0.0, 3, 80**************
53.92882947976879, 2.1947254335260116, 128.6952070932539, 0.0, 3, 79
53.91979768786127, 2.1947254335260116, 128.71869878400534, 0.0, 3, 78
53.91076589595376, 2.1947254335260116, 128.8024957493232, 0.0, 3, 77
53.91076589595376, 2.1947254335260116, 128.8147127531768, 0.0, 3, 76
53.793352601156066, 2.1947254335260116, 127.70903358392948, 0.0, 4, 95
53.793352601156066, 2.1947254335260116, 127.70903358392948, 0.0, 4, 94
53.793352601156066, 2.1947254335260116, 127.72155014221465, 0.0, 4, 93
53.793352601156066, 2.1947254335260116, 127.72155014221465, 0.0, 4, 92
53.793352601156066, 2.1947254335260116, 127.72155014221465, 0.0, 4, 91
53.793352601156066, 2.1947254335260116, 127.72155014221465, 0.0, 4, 90
53.793352601156066, 2.1947254335260116, 127.72158024818768, 0.0, 4, 89
53.793352601156066, 2.1947254335260116, 127.72200173181002, 0.0, 4, 88
53.793352601156066, 2.1947254335260116, 127.72337155358268, 0.0, 4, 87
53.793352601156066, 2.1947254335260116, 127.7393931997773, 0.0, 4, 86
53.80238439306358, 2.1947254335260116, 127.7448499073881, 0.0, 4, 85
53.80238439306358, 2.1947254335260116, 127.750163611627, 0.0, 4, 84
53.784320809248555, 2.1947254335260116, 127.81516154721744, 0.0, 4, 83
53.91076589595376, 2.1947254335260116, 127.83529115343136, 0.0, 4, 82
53.92882947976879, 2.1947254335260116, 128.59547385367915, 0.0, 4, 81
53.92882947976879, 2.1947254335260116, 128.66256135884018, 0.0, 4, 80
53.91979768786127, 2.1947254335260116, 128.69632370228916, 0.0, 4, 79
53.91076589595376, 2.1947254335260116, 128.7199057109597, 0.0, 4, 78
53.90173410404624, 2.1947254335260116, 128.80370267627757, 0.0, 4, 77
53.90173410404624, 2.1947254335260116, 128.81731960787678, 0.0, 4, 76
53.793352601156066, 2.1947254335260116, 127.70903358392948, 0.0, 5, 95
53.793352601156066, 2.1947254335260116, 127.70903358392948, 0.0, 5, 94
53.793352601156066, 2.1947254335260116, 127.72155014221465, 0.0, 5, 93
53.793352601156066, 2.1947254335260116, 127.72155014221465, 0.0, 5, 92
53.793352601156066, 2.1947254335260116, 127.72155014221465, 0.0, 5, 91
53.793352601156066, 2.1947254335260116, 127.72155014221465, 0.0, 5, 90
53.793352601156066, 2.1947254335260116, 127.72158024818768, 0.0, 5, 89
53.793352601156066, 2.1947254335260116, 127.72200173181002, 0.0, 5, 88
53.793352601156066, 2.1947254335260116, 127.72337155358268, 0.0, 5, 87
53.793352601156066, 2.1947254335260116, 127.73957383561545, 0.0, 5, 86
53.80238439306358, 2.1947254335260116, 127.74503054322626, 0.0, 5, 85
53.80238439306358, 2.1947254335260116, 127.75084099602009, 0.0, 5, 84
53.784320809248555, 2.1947254335260116, 127.81583893161051, 0.0, 5, 83
53.91076589595376, 2.1947254335260116, 127.83596853782443, 0.0, 5, 82
53.92882947976879, 2.1947254335260116, 128.59615123807222, 0.0, 5, 81
53.92882947976879, 2.1947254335260116, 128.66323874323325, 0.0, 5, 80
53.91979768786127, 2.1947254335260116, 128.69700108668226, 0.0, 5, 79
53.91076589595376, 2.1947254335260116, 128.72058309535277, 0.0, 5, 78
53.90173410404624, 2.1947254335260116, 128.8044703785897, 0.0, 5, 77
53.90173410404624, 2.1947254335260116, 128.8197130327323, 0.0, 5, 76
53.793352601156066, 2.1947254335260116, 127.70903358392948, 0.0, 6, 95
53.793352601156066, 2.1947254335260116, 127.70903358392948, 0.0, 6, 94
53.793352601156066, 2.1947254335260116, 127.72155014221465, 0.0, 6, 93
53.793352601156066, 2.1947254335260116, 127.72155014221465, 0.0, 6, 92
53.793352601156066, 2.1947254335260116, 127.72155014221465, 0.0, 6, 91
53.793352601156066, 2.1947254335260116, 127.72155014221465, 0.0, 6, 90
53.793352601156066, 2.1947254335260116, 127.72158024818768, 0.0, 6, 89
53.793352601156066, 2.1947254335260116, 127.72200173181002, 0.0, 6, 88
53.793352601156066, 2.1947254335260116, 127.72337155358268, 0.0, 6, 87
53.793352601156066, 2.1947254335260116, 127.73957383561545, 0.0, 6, 86
53.80238439306358, 2.1947254335260116, 127.74521117906441, 0.0, 6, 85
53.80238439306358, 2.1947254335260116, 127.75102163185824, 0.0, 6, 84
53.784320809248555, 2.1947254335260116, 127.81624536224635, 0.0, 6, 83
53.91076589595376, 2.1947254335260116, 127.8364201274198, 0.0, 6, 82
53.92882947976879, 2.1947254335260116, 128.5966028276676, 0.0, 6, 81
53.92882947976879, 2.1947254335260116, 128.66369033282862, 0.0, 6, 80
53.91979768786127, 2.1947254335260116, 128.6975429941967, 0.0, 6, 79
53.91076589595376, 2.1947254335260116, 128.7211250028672, 0.0, 6, 78
53.90173410404624, 2.1947254335260116, 128.8051929219423, 0.0, 6, 77
53.90173410404624, 2.1947254335260116, 128.8204355760849, 0.0, 6, 76
53.793352601156066, 2.1947254335260116, 127.70903358392948, 0.0, 7, 95
53.793352601156066, 2.1947254335260116, 127.70903358392948, 0.0, 7, 94
53.793352601156066, 2.1947254335260116, 127.72155014221465, 0.0, 7, 93
53.793352601156066, 2.1947254335260116, 127.72155014221465, 0.0, 7, 92
53.793352601156066, 2.1947254335260116, 127.72155014221465, 0.0, 7, 91
53.793352601156066, 2.1947254335260116, 127.72155014221465, 0.0, 7, 90
53.793352601156066, 2.1947254335260116, 127.72158024818768, 0.0, 7, 89
53.793352601156066, 2.1947254335260116, 127.72200173181002, 0.0, 7, 88
53.793352601156066, 2.1947254335260116, 127.72337155358268, 0.0, 7, 87
53.793352601156066, 2.1947254335260116, 127.73957383561545, 0.0, 7, 86
53.80238439306358, 2.1947254335260116, 127.74557245074071, 0.0, 7, 85
53.80238439306358, 2.1947254335260116, 127.75138290353455, 0.0, 7, 84
53.784320809248555, 2.1947254335260116, 127.81687758767987, 0.0, 7, 83
53.91076589595376, 2.1947254335260116, 127.83705235285332, 0.0, 7, 82
53.92882947976879, 2.1947254335260116, 128.59723505310114, 0.0, 7, 81
53.92882947976879, 2.1947254335260116, 128.66432255826217, 0.0, 7, 80
53.91979768786127, 2.1947254335260116, 128.6982655375493, 0.0, 7, 79
53.91076589595376, 2.1947254335260116, 128.72184754621983, 0.0, 7, 78
53.90173410404624, 2.1947254335260116, 128.8059154652949, 0.0, 7, 77
53.90173410404624, 2.1947254335260116, 128.8211581194375, 0.0, 7, 76
53.793352601156066, 2.1947254335260116, 127.70903358392948, 0.0, 8, 95
53.793352601156066, 2.1947254335260116, 127.70903358392948, 0.0, 8, 94
53.793352601156066, 2.1947254335260116, 127.72155014221465, 0.0, 8, 93
53.793352601156066, 2.1947254335260116, 127.72155014221465, 0.0, 8, 92
53.793352601156066, 2.1947254335260116, 127.72155014221465, 0.0, 8, 91
53.793352601156066, 2.1947254335260116, 127.72155014221465, 0.0, 8, 90
53.793352601156066, 2.1947254335260116, 127.72158024818768, 0.0, 8, 89
53.793352601156066, 2.1947254335260116, 127.72200173181002, 0.0, 8, 88
53.793352601156066, 2.1947254335260116, 127.72337155358268, 0.0, 8, 87
53.793352601156066, 2.1947254335260116, 127.73957383561545, 0.0, 8, 86
53.80238439306358, 2.1947254335260116, 127.74557245074071, 0.0, 8, 85
53.80238439306358, 2.1947254335260116, 127.75138290353455, 0.0, 8, 84
53.784320809248555, 2.1947254335260116, 127.81702811754501, 0.0, 8, 83
53.91076589595376, 2.1947254335260116, 127.83729320063753, 0.0, 8, 82
53.92882947976879, 2.1947254335260116, 128.59798770242676, 0.0, 8, 81
53.92882947976879, 2.1947254335260116, 128.6650752075878, 0.0, 8, 80
53.91979768786127, 2.1947254335260116, 128.699108504794, 0.0, 8, 79
53.91076589595376, 2.1947254335260116, 128.72269051346453, 0.0, 8, 78
53.90173410404624, 2.1947254335260116, 128.8067584325396, 0.0, 8, 77
53.90173410404624, 2.1947254335260116, 128.8220010866822, 0.0, 8, 76

// Run large step experiment again, no segmenting and fixed filter_threshold
Match percentage, Zeros percentage, Average score, Filter Threshold %, Num similar terms, Min similarity %,
C:\msys64\mingw64\lib\python3.8\site-packages\gensim\similarities\index.py:159: FutureWarning: The default argument for metric will be removed in future version of Annoy. Please pass metric='angular' explicitly.
  self.index = AnnoyIndex(d['f'])
53.80238439306358, 2.1947254335260116, 88.91492324410427, 0.0, 1, 95
53.80238439306358, 2.1947254335260116, 88.91492324410427, 0.0, 1, 90
53.80238439306358, 2.1947254335260116, 88.91492324410427, 0.0, 1, 85
53.80238439306358, 2.1947254335260116, 88.91492324410427, 0.0, 1, 80
53.80238439306358, 2.1947254335260116, 88.91496840306381, 0.0, 1, 75
53.80238439306358, 2.1947254335260116, 88.91569094641642, 0.0, 1, 70
53.80238439306358, 2.1947254335260116, 88.91587158225457, 0.0, 1, 65
53.80238439306358, 2.1947254335260116, 88.91587158225457, 0.0, 1, 60
53.8114161849711, 2.1947254335260116, 88.91821984815051, 0.0, 1, 55
53.8114161849711, 2.1947254335260116, 88.91876175566497, 0.0, 1, 50
53.80238439306358, 2.1947254335260116, 88.91492324410427, 0.0, 3, 95
53.80238439306358, 2.1947254335260116, 88.92425609574204, 0.0, 3, 90
53.8114161849711, 2.1947254335260116, 88.94570767673568, 0.0, 3, 85
53.90173410404624, 2.1947254335260116, 89.50532861386296, 0.0, 3, 80
53.88367052023121, 2.1947254335260116, 89.68380262810741, 0.0, 3, 75
53.91076589595376, 2.1947254335260116, 90.11801803060985, 0.0, 3, 70
53.8746387283237, 2.1947254335260116, 92.2102539152094, 0.0, 3, 65
53.77528901734104, 2.1947254335260116, 96.24855082748351, 0.0, 3, 60
53.621748554913296, 2.1947254335260116, 100.45619057654304, 0.0, 3, 55
53.14306358381503, 2.1947254335260116, 106.43287091992327, 0.0, 3, 50
53.80238439306358, 2.1947254335260116, 88.91492324410427, 0.0, 5, 95
53.80238439306358, 2.1947254335260116, 88.92425609574204, 0.0, 5, 90
53.80238439306358, 2.1947254335260116, 88.94607163644528, 0.0, 5, 85
53.89270231213873, 2.1947254335260116, 89.50629469303307, 0.0, 5, 80
53.8746387283237, 2.1947254335260116, 89.7018026668151, 0.0, 5, 75
(((((((((((((((((53.91076589595376, 2.1947254335260116, 90.17075111535388, 0.0, 5, 70
53.88367052023121, 2.1947254335260116, 92.59905105256155, 0.0, 5, 65
53.57658959537572, 2.1947254335260116, 98.071180878119, 0.0, 5, 60
53.37789017341041, 2.1947254335260116, 104.77804944834345, 0.0, 5, 55
52.456647398843934, 2.1947254335260116, 115.18172381067035, 0.0, 5, 50
53.80238439306358, 2.1947254335260116, 88.91492324410427, 0.0, 7, 95
53.80238439306358, 2.1947254335260116, 88.92425609574204, 0.0, 7, 90
53.80238439306358, 2.1947254335260116, 88.9462071133239, 0.0, 7, 85
53.89270231213873, 2.1947254335260116, 89.50665596470937, 0.0, 7, 80
53.88367052023121, 2.1947254335260116, 89.70356666179171, 0.0, 7, 75
((((((((((((((((((53.91076589595376, 2.1947254335260116, 90.17804622270317, 0.0, 7, 70
53.8746387283237, 2.1947254335260116, 92.61486045164635, 0.0, 7, 65
53.57658959537572, 2.1947254335260116, 98.6772919605577, 0.0, 7, 60
53.233381502890175, 2.1947254335260116, 106.04347811439072, 0.0, 7, 55
52.230852601156066, 2.1947254335260116, 120.15631795348149, 0.0, 7, 50
53.80238439306358, 2.1947254335260116, 88.91492324410427, 0.0, 9, 95
53.80238439306358, 2.1947254335260116, 88.92425609574204, 0.0, 9, 90
53.80238439306358, 2.1947254335260116, 88.9462071133239, 0.0, 9, 85
53.89270231213873, 2.1947254335260116, 89.50743872000801, 0.0, 9, 80
53.8746387283237, 2.1947254335260116, 89.70612566949885, 0.0, 9, 75
53.90173410404624, 2.1947254335260116, 90.18672878532361, 0.0, 9, 70
53.84754335260116, 2.1947254335260116, 92.62661414607933, 0.0, 9, 65
53.52239884393064, 2.1947254335260116, 98.74964177476085, 0.0, 9, 60
53.1882225433526, 2.1947254335260116, 106.8563170574702, 0.0, 9, 55
52.1224710982659, 2.1947254335260116, 124.1878166861633, 0.0, 9, 50

// Performing a deeper scan on the best of above gives

53.8746387283237, 2.1947254335260116, 89.69942429494613, 0.0, 4, 75
53.865606936416185, 2.1947254335260116, 89.8397587723064, 0.0, 4, 74
53.88367052023121, 2.1947254335260116, 89.8932751141153, 0.0, 4, 73
53.89270231213873, 2.1947254335260116, 89.9540240216985, 0.0, 4, 72
53.89270231213873, 2.1947254335260116, 90.03247115560987, 0.0, 4, 71
53.90173410404624, 2.1947254335260116, 90.16697002018459, 0.0, 4, 70
53.91076589595376, 2.1947254335260116, 90.3155796618375, 0.0, 4, 69
53.90173410404624, 2.1947254335260116, 90.82582031608337, 0.0, 4, 68
53.91979768786127, 2.1947254335260116, 91.32204384433133, 0.0, 4, 67
53.88367052023121, 2.1947254335260116, 92.31823551042466, 0.0, 4, 66
53.88367052023121, 2.1947254335260116, 92.57760054678118, 0.0, 4, 65
53.8746387283237, 2.1947254335260116, 89.7018026668151, 0.0, 5, 75
53.865606936416185, 2.1947254335260116, 89.84231778001352, 0.0, 5, 74
53.89270231213873, 2.1947254335260116, 89.89592723529614, 0.0, 5, 73
53.90173410404624, 2.1947254335260116, 89.95757932207009, 0.0, 5, 72
53.90173410404624, 2.1947254335260116, 90.03620709181962, 0.0, 5, 71
53.91076589595376, 2.1947254335260116, 90.17075111535388, 0.0, 5, 70
53.91979768786127, 2.1947254335260116, 90.31940591596633, 0.0, 5, 69
53.91076589595376, 2.1947254335260116, 90.8365107320619, 0.0, 5, 68
53.92882947976879, 2.1947254335260116, 91.33623407967401, 0.0, 5, 67
53.88367052023121, 2.1947254335260116, 92.33251326813179, 0.0, 5, 66
53.88367052023121, 2.1947254335260116, 92.59905105256155, 0.0, 5, 65
53.88367052023121, 2.1947254335260116, 89.70270864156049, 0.0, 6, 75
53.8746387283237, 2.1947254335260116, 89.84322375475891, 0.0, 6, 74
53.89270231213873, 2.1947254335260116, 89.89735167790555, 0.0, 6, 73
53.90173410404624, 2.1947254335260116, 89.95971125504559, 0.0, 6, 72
53.90173410404624, 2.1947254335260116, 90.0395131577431, 0.0, 6, 71
53.91076589595376, 2.1947254335260116, 90.17414749919644, 0.0, 6, 70
53.91979768786127, 2.1947254335260116, 90.3229377766875, 0.0, 6, 69
53.91076589595376, 2.1947254335260116, 90.84017806966168, 0.0, 6, 68
53.92882947976879, 2.1947254335260116, 91.34123360658016, 0.0, 6, 67
53.8746387283237, 2.1947254335260116, 92.33866241312217, 0.0, 6, 66
53.8746387283237, 2.1947254335260116, 92.60759362240742, 0.0, 6, 65
53.88367052023121, 2.1947254335260116, 89.70356666179171, 0.0, 7, 75
53.88367052023121, 2.1947254335260116, 89.84439229659762, 0.0, 7, 74
53.89270231213873, 2.1947254335260116, 89.89903761239495, 0.0, 7, 73
53.90173410404624, 2.1947254335260116, 89.96148750745407, 0.0, 7, 72
53.90173410404624, 2.1947254335260116, 90.04268933789723, 0.0, 7, 71
53.91076589595376, 2.1947254335260116, 90.17804622270317, 0.0, 7, 70
53.91979768786127, 2.1947254335260116, 90.32766441445244, 0.0, 7, 69
53.91076589595376, 2.1947254335260116, 90.84517566118384, 0.0, 7, 68
53.92882947976879, 2.1947254335260116, 91.34734210850695, 0.0, 7, 67
53.88367052023121, 2.1947254335260116, 92.3443610437305, 0.0, 7, 66


// Turning segmentation back on and testing if DB still works
// Had to fix a couple bugs introduced while adding w2v support
//      1) Eliminate duplicates from sim_words lists
//      2) Make sure list returned from similar function is of strings (not of tuples, like fetchall returns))
// Now there actually is some response to variables, but it is very small
// Looks like only num_similar has any effect for DB

Match percentage, Zeros percentage, Average score, Filter Threshold %, Num similar terms, Min similarity %,
53.50433526011561, 2.1947254335260116, 134.9027129782543, 0.0, 1, 95
53.50433526011561, 2.1947254335260116, 134.9027129782543, 0.0, 1, 90
...
53.50433526011561, 2.1947254335260116, 134.9027129782543, 0.0, 1, 50
52.86307803468208, 2.1947254335260116, 148.2682636451742, 0.0, 3, 95
...
52.29407514450867, 2.1947254335260116, 163.00852701509382, 0.0, 5, 95
...
51.842485549132945, 2.1947254335260116, 177.50007433308133, 0.0, 7, 95
...
51.779263005780344, 2.1947254335260116, 192.27775888986386, 0.0, 9, 95


// Segmentation disabled, slightly better results

Match percentage, Zeros percentage, Average score, Filter Threshold %, Num similar terms, Min similarity %,
53.486271676300575, 2.1947254335260116, 92.53930979906316, 0.0, 1, 100
53.486271676300575, 2.1947254335260116, 92.53930979906316, 0.0, 1, 90
53.486271676300575, 2.1947254335260116, 92.53930979906316, 0.0, 1, 80
53.486271676300575, 2.1947254335260116, 92.53930979906316, 0.0, 1, 70
53.486271676300575, 2.1947254335260116, 92.53930979906316, 0.0, 1, 60
53.486271676300575, 2.1947254335260116, 92.53930979906316, 0.0, 1, 50
52.94436416184971, 2.1947254335260116, 99.37637276068851, 0.0, 3, 100
52.94436416184971, 2.1947254335260116, 99.37637276068851, 0.0, 3, 90
52.94436416184971, 2.1947254335260116, 99.37637276068851, 0.0, 3, 80
52.94436416184971, 2.1947254335260116, 99.37637276068851, 0.0, 3, 70
52.94436416184971, 2.1947254335260116, 99.37637276068851, 0.0, 3, 60
52.94436416184971, 2.1947254335260116, 99.37637276068851, 0.0, 3, 50
52.465679190751445, 2.1947254335260116, 106.80911805985569, 0.0, 5, 100
52.465679190751445, 2.1947254335260116, 106.80911805985569, 0.0, 5, 90
52.465679190751445, 2.1947254335260116, 106.80911805985569, 0.0, 5, 80
52.465679190751445, 2.1947254335260116, 106.80911805985569, 0.0, 5, 70
52.465679190751445, 2.1947254335260116, 106.80911805985569, 0.0, 5, 60
52.465679190751445, 2.1947254335260116, 106.80911805985569, 0.0, 5, 50
52.1856936416185, 2.1947254335260116, 113.91030910949378, 0.0, 7, 100
52.1856936416185, 2.1947254335260116, 113.91030910949378, 0.0, 7, 90
52.1856936416185, 2.1947254335260116, 113.91030910949378, 0.0, 7, 80
52.1856936416185, 2.1947254335260116, 113.91030910949378, 0.0, 7, 70
52.1856936416185, 2.1947254335260116, 113.91030910949378, 0.0, 7, 60
52.1856936416185, 2.1947254335260116, 113.91030910949378, 0.0, 7, 50
52.02312138728324, 2.1947254335260116, 120.95591471264599, 0.0, 9, 100
52.02312138728324, 2.1947254335260116, 120.95591471264599, 0.0, 9, 90
52.02312138728324, 2.1947254335260116, 120.95591471264599, 0.0, 9, 80
52.02312138728324, 2.1947254335260116, 120.95591471264599, 0.0, 9, 70
52.02312138728324, 2.1947254335260116, 120.95591471264599, 0.0, 9, 60
52.02312138728324, 2.1947254335260116, 120.95591471264599, 0.0, 9, 50

// Raw tf-idf with final code
53.793352601156066, 2.1947254335260116, 127.70903358392948, 0.0, 1, 0


// Testing not using set() with input documents in generate_frequencies
<deleted>

// After tweaking classify_test.py to use options from command line and making configurations
// Rerunning experiments due to lost labels and for completeness
// First row rough best, 2nd fine search (best rough as midpoint between adjacent, no points skipped)

Raw, True:  54.29913294797688, 2.1947254335260116, 184.6757804973521, 0.0, 1, 0, 0.005071573303958584  (scans here are pointless)
Raw, False: 53.92882947976879, 2.1947254335260116, 107.84293663696215, 0.0, 1, 20, 0.00036579753794422037 (picked middling time))
DB,  True:  53.95592485549133, 2.1947254335260116, 191.6938075955946, 0.0, 1, 0, 0.017251953654895628   (all min sim same result, stopped at 5 terms))
DB,  False: 53.65787572254335, 2.1947254335260116, 111.91402325471384, 0.0, 1, 30, 0.013960630046149898

W2V, True:  54.416546242774565, 2.1947254335260116, 185.63481056891808, 0.0, 3, 80, 0.007895431271350452
            54.416546242774565, 2.1947254335260116, 185.63666208625915, 0.0, 5, 80, 0.009728024934413116

            54.42557803468208, 2.1947254335260116, 184.80861908919536, 0.0, 4, 82, 0.017305385687447696
            54.42557803468208, 2.1947254335260116, 184.8092964735884, 0.0, 5, 82, 0.006464258073210027

W2V, False: 54.028179190751445, 2.1947254335260116, 109.17517970398688, 0.0, 5, 70, 0.0017131215790448162
            54.028179190751445, 2.1947254335260116, 108.46138023700586, 0.0, 5, 80, 0.002045575981539798

            54.03721098265896, 2.1947254335260116, 108.95333276705455, 0.0, 5, 72, 0.001361450406512773
